{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd3d70a8-4ef5-4be6-92aa-63192b8db1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipywidgets) (8.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.12 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: executing in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "#Primero importamos algunas librerias necesarias para el procesamiento de los códigos:\n",
    "\n",
    "!pip install ipywidgets\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b739a2-9d0a-4f70-9859-58d99f6a1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seguimos... \n",
    "\n",
    "# Imports de ML/embeddings - deben estar instalados\n",
    "try:\n",
    " from sentence_transformers import SentenceTransformer # para generar embeddings \n",
    "except Exception as e:\n",
    " SentenceTransformer = None\n",
    "try:\n",
    " import tiktoken #para contar tokens\n",
    "except Exception:\n",
    " tiktoken = None\n",
    "try:\n",
    " import chromadb # para la base de datos vectorial \n",
    " from chromadb.config import Settings\n",
    " from chromadb.utils import embedding_functions #funciones de embeddings\n",
    "except Exception:\n",
    " chromadb = None\n",
    "# LangChain - conecta los pasos en un pipeline\n",
    "try:\n",
    " from langchain.schema import Document\n",
    " from langchain.embeddings import SentenceTransformerEmbeddings\n",
    " from langchain.vectorstores import Chroma\n",
    " from langchain.chains import SimpleSequentialChain, LLMChain\n",
    " from langchain.prompts import PromptTemplate\n",
    " from langchain.llms import OpenAI\n",
    "except Exception:\n",
    "\n",
    " pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab62e2e-cc86-4b34-91bf-d2dbf3a5e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuración inicial: \n",
    "RPP_RSS_URL = \"https://rpp.pe/rss\"\n",
    "MAX_ITEMS = 50\n",
    "PERSIST_DIRECTORY = \"./chroma_rpp_db\"\n",
    "CHROMA_COLLECTION_NAME = \"rpp_news\"\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e338d480-29e3-4bc1-92d1-f9d989da4953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#Cargamos la data: Parseamos el feed RSS y extraemos hasta 50 (max items) entradas\n",
    "\n",
    "def fetch_rss_items(rss_url: str, max_items: int = 50):\n",
    "    try:\n",
    "        # ⚙️ Usa requests para obtener el XML ignorando SSL\n",
    "        response = requests.get(rss_url, verify=False, timeout=10)\n",
    "        response.raise_for_status()  # error si el request falla\n",
    "        feed = feedparser.parse(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al descargar o parsear feed: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    entries = feed.get(\"entries\", [])[:max_items]\n",
    "    records = [] #lista para almacenar los datos\n",
    "    for e in entries:\n",
    "        title = e.get(\"title\", \"\") #título\n",
    "        description = e.get(\"description\", \"\") #descripción\n",
    "        link = e.get(\"link\", \"\") #enlace\n",
    "        published = e.get(\"published\", \"\") #fecha de publicación\n",
    "        #Normalizamos la fecha si esta en formato parsed\n",
    "        try:\n",
    "            published_parsed = e.get(\"published_parsed\")\n",
    "            if published_parsed:\n",
    "                published = datetime(*published_parsed[:6]).isoformat()\n",
    "        except Exception:\n",
    "            pass\n",
    "        records.append({\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "            \"link\": link,\n",
    "            \"date_published\": published,\n",
    "        })\n",
    "    return pd.DataFrame(records) #convertimos a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c1cfe18-91d3-4823-8028-ee54a942ab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajoaq\\anaconda3\\envs\\task_1\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'rpp.pe'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 50 items\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "      <th>date_published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nicolás Maduro anuncia nuevos ejercicios milit...</td>\n",
       "      <td>Maduro sostuvo que a la medianoche de este jue...</td>\n",
       "      <td>https://rpp.pe/mundo/actualidad/nicolas-maduro...</td>\n",
       "      <td>2025-10-23T22:47:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Latin Billboard 2025: lista completa de nomina...</td>\n",
       "      <td>En esta edición, Bad Bunny encabeza las nomina...</td>\n",
       "      <td>https://rpp.pe/musica/internacional/latin-bill...</td>\n",
       "      <td>2025-10-23T22:45:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Universitario vs. Sporting Cristal hoy EN VIVO...</td>\n",
       "      <td>Sporting Cristal recibe a Universitario en un ...</td>\n",
       "      <td>https://rpp.pe/futbol/descentralizado/universi...</td>\n",
       "      <td>2025-10-23T22:45:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cristian Castro jugó fútbol con sus fans en Li...</td>\n",
       "      <td>¡Ya está en Lima! A pocas horas de su conciert...</td>\n",
       "      <td>https://rpp.pe/famosos/celebridades/cristian-c...</td>\n",
       "      <td>2025-10-23T21:42:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cronograma del octavo retiro de AFP 2025 sigue...</td>\n",
       "      <td>El desembolso se efectuará hasta en cuatro arm...</td>\n",
       "      <td>https://rpp.pe/economia/economia/octavo-retiro...</td>\n",
       "      <td>2025-10-23T22:40:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Nicolás Maduro anuncia nuevos ejercicios milit...   \n",
       "1  Latin Billboard 2025: lista completa de nomina...   \n",
       "2  Universitario vs. Sporting Cristal hoy EN VIVO...   \n",
       "3  Cristian Castro jugó fútbol con sus fans en Li...   \n",
       "4  Cronograma del octavo retiro de AFP 2025 sigue...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Maduro sostuvo que a la medianoche de este jue...   \n",
       "1  En esta edición, Bad Bunny encabeza las nomina...   \n",
       "2  Sporting Cristal recibe a Universitario en un ...   \n",
       "3  ¡Ya está en Lima! A pocas horas de su conciert...   \n",
       "4  El desembolso se efectuará hasta en cuatro arm...   \n",
       "\n",
       "                                                link       date_published  \n",
       "0  https://rpp.pe/mundo/actualidad/nicolas-maduro...  2025-10-23T22:47:59  \n",
       "1  https://rpp.pe/musica/internacional/latin-bill...  2025-10-23T22:45:15  \n",
       "2  https://rpp.pe/futbol/descentralizado/universi...  2025-10-23T22:45:08  \n",
       "3  https://rpp.pe/famosos/celebridades/cristian-c...  2025-10-23T21:42:51  \n",
       "4  https://rpp.pe/economia/economia/octavo-retiro...  2025-10-23T22:40:03  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RPP_RSS_URL = \"https://rpp.pe/rss\"\n",
    "df = fetch_rss_items(RPP_RSS_URL, 50)\n",
    "print(f\"Fetched {len(df)} items\")\n",
    "df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089ab53e-78f8-4027-b59f-f023e97bd3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# TOKENIZATION: un articulo de ejemplo utilizando tiktoken\n",
    "def count_tokens_tiktoken(text: str, model_name: str = \"gpt-4o-mini\") -> int:\n",
    "    \"\"\"\n",
    "    Use tiktoken if available. Provide a fallback token estimation (approx 4 chars/token).\n",
    "    \"\"\"\n",
    "    if tiktoken is None:\n",
    "        return max(1, math.ceil(len(text) / 4))\n",
    "    try:\n",
    "        enc = tiktoken.encoding_for_model(model_name)\n",
    "    except Exception:\n",
    "        try:\n",
    "            enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        except Exception:\n",
    "            return max(1, math.ceil(len(text) / 4))\n",
    "    return len(enc.encode(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a40d95cf-3685-41c4-9ef9-f2906792c24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokens: 70\n"
     ]
    }
   ],
   "source": [
    "# Creamos un \"sample\" de texto del primer item RSS\n",
    "sample_text = (df.loc[0, \"title\"] or \"\") + \"\\n\\n\" + (df.loc[0, \"description\"] or \"\")\n",
    "\n",
    "num_tokens = count_tokens_tiktoken(sample_text)\n",
    "print(\"Sample tokens:\", num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed0df50e-f01e-4de4-9830-4a1fb7d56640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needs chunking? False\n"
     ]
    }
   ],
   "source": [
    "# Decidimos si el chinking se necesita\n",
    "MODEL_TOKEN_LIMIT = 4096\n",
    "CHUNK_TOKEN_TARGET = 1000  # target de tokens por chunk\n",
    "needs_chunking = num_tokens > CHUNK_TOKEN_TARGET\n",
    "print(\"Needs chunking?\", needs_chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff7f906-0738-4f88-8d1d-2759f5019c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking helper (naive words-based — can replace with tiktoken-based chunker)\n",
    "def chunk_text(text: str, chunk_size_chars: int = 2000):\n",
    "    \"\"\"Naive chunk by characters preserving whole words.\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    cur = []\n",
    "    cur_len = 0\n",
    "    for w in words:\n",
    "        if cur_len + len(w) + 1 > chunk_size_chars:\n",
    "            chunks.append(\" \".join(cur))\n",
    "            cur = [w]\n",
    "            cur_len = len(w) + 1\n",
    "        else:\n",
    "            cur.append(w)\n",
    "            cur_len += len(w) + 1\n",
    "    if cur:\n",
    "        chunks.append(\" \".join(cur))\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Example chunk preview\n",
    "if needs_chunking:\n",
    "    chunks = chunk_text(sample_text, chunk_size_chars=1500)\n",
    "    print(\"Chunks created:\", len(chunks))\n",
    "    for i, c in enumerate(chunks[:2]):\n",
    "        print(i, \"len chars:\", len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ac1b4d3-70ca-48e3-9b21-90fd07d3a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "\n",
    "# EMBEDDING: Utilizamos SentenceTransformers\n",
    "def load_sentence_transformer(model_name: str = EMBEDDING_MODEL_NAME):\n",
    "    #Cargamos el modelo SentenceTransformers\n",
    "    if SentenceTransformer is None:\n",
    "        raise ImportError(\"sentence-transformers not installed. Install from requirements.txt\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fcbdcda-46b5-4025-bde7-3e9625492d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings model wrapper\n",
    "class EmbeddingModel:\n",
    "    def __init__(self, model_name=EMBEDDING_MODEL_NAME):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "\n",
    "    def load(self):\n",
    "        self.model = load_sentence_transformer(self.model_name)\n",
    "\n",
    "    def embed_texts(self, texts: list) -> np.ndarray:\n",
    "        if self.model is None:\n",
    "            self.load()\n",
    "        return np.array(self.model.encode(texts, show_progress_bar=True)) #genera embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2513e22-84c4-4737-99c9-2e0a7501d125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de documentos para el embed: 50\n",
      "Ejemplo de doc.: {'id': '0', 'text': 'Nicolás Maduro anuncia nuevos ejercicios militares en las costas de Venezuela por 72 horas\\n\\nMaduro sostuvo que a la medianoche de este jueves llamó a \"quienes tenía que llamar\" y dio la orden de activar todos los equipos militares \"de inmediato\" para la defensa de los \"puntos de acción\" en toda la costa de Venezuela.', 'metadata': {'orig_index': 0, 'chunk_id': 0, 'title': 'Nicolás Maduro anuncia nuevos ejercicios militares en las costas de Venezuela por 72 horas', 'link': 'https://rpp.pe/mundo/actualidad/nicolas-maduro-anuncia-nuevos-ejercicios-militares-en-las-costas-de-venezuela-por-72-horas-noticia-1660705', 'date_published': '2025-10-23T22:47:59'}}\n"
     ]
    }
   ],
   "source": [
    "# Preparamos documentos para el embed: combinamos título + descripción, chunking si es necesario\n",
    "docs = []\n",
    "for idx, row in df.iterrows():\n",
    "    text = (row[\"title\"] or \"\") + \"\\n\\n\" + (row[\"description\"] or \"\")\n",
    "    if count_tokens_tiktoken(text) > CHUNK_TOKEN_TARGET:\n",
    "        text_chunks = chunk_text(text, chunk_size_chars=1500)\n",
    "        for ci, c in enumerate(text_chunks):\n",
    "            docs.append({\n",
    "                \"id\": f\"{idx}_chunk{ci}\",\n",
    "                \"text\": c,\n",
    "                \"metadata\": {\n",
    "                    \"orig_index\": int(idx),\n",
    "                    \"chunk_id\": ci,\n",
    "                    \"title\": row[\"title\"],\n",
    "                    \"link\": row[\"link\"],\n",
    "                    \"date_published\": row[\"date_published\"],\n",
    "                },\n",
    "            })\n",
    "    else:\n",
    "        docs.append({\n",
    "            \"id\": f\"{idx}\",\n",
    "            \"text\": text,\n",
    "            \"metadata\": {\n",
    "                \"orig_index\": int(idx),\n",
    "                \"chunk_id\": 0,\n",
    "                \"title\": row[\"title\"],\n",
    "                \"link\": row[\"link\"],\n",
    "                \"date_published\": row[\"date_published\"],\n",
    "            },\n",
    "        })\n",
    "\n",
    "print(\"Total de documentos para el embed:\", len(docs))\n",
    "print(\"Ejemplo de doc.:\", docs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97211464-698d-4a33-bf38-9d6fe03a4828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (50, 384)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "emb = EmbeddingModel() #Creamos instancia del modelo de embeddings\n",
    "\n",
    "# Para demo/testeo:\n",
    "embeddings = np.random.randn(len(docs), 384).astype(np.float32)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa48fc1e-d7b3-4612-9b92-1deba4334c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos collección Chroma:\n",
    "def init_chroma(persist_directory: str = PERSIST_DIRECTORY, embedding_function=None):\n",
    "    \n",
    "    # Verificar instalación de chromadb\n",
    "    try:\n",
    "        import chromadb\n",
    "        from chromadb.config import Settings\n",
    "    except ImportError:\n",
    "        raise ImportError(\"chromadb not installed. Please install it via 'pip install chromadb'.\")\n",
    "\n",
    "    # Creamos cliente con configuración\n",
    "    client = chromadb.Client(\n",
    "        Settings(\n",
    "            chroma_db_impl=\"duckdb+parquet\",\n",
    "            persist_directory=persist_directory\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Creamos o recuperamos colección\n",
    "    collection = client.get_or_create_collection(\n",
    "        name=CHROMA_COLLECTION_NAME,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "\n",
    "    return client, collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2279a30b-c14e-4108-a0a0-15b0ecfc6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados Query: ejemplo de busqueda por similitud\n",
    "def chroma_similarity_search(collection, query_embedding, top_k=5):\n",
    "    \"\"\"\n",
    "    Ejecuta una búsqueda de similitud en una colección de Chroma.\n",
    "    Retorna los resultados más similares según el embedding de consulta.\n",
    "    \"\"\"\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding.tolist()],\n",
    "        n_results=top_k,\n",
    "        include=['metadatas', 'documents', 'distances']\n",
    "    )\n",
    "    return results\n",
    "\n",
    "\n",
    "# Convertimos resultados de Chroma a DataFrame legible:\n",
    "def results_to_dataframe(results):\n",
    "    \"\"\"\n",
    "    Convierte los resultados de una búsqueda en Chroma a un DataFrame\n",
    "    con columnas: title, description, link, date_published.\n",
    "    \"\"\"\n",
    "    hits = []\n",
    "\n",
    "    # results ... estructura: dict con 'ids', 'documents', 'metadatas', 'distances' — listas por query\n",
    "    if not results or not results.get('ids'):\n",
    "        return pd.DataFrame(columns=['title', 'description', 'link', 'date_published'])\n",
    "\n",
    "    for i in range(len(results['ids'][0])):\n",
    "        meta = results['metadatas'][0][i]\n",
    "        doc_text = results['documents'][0][i]\n",
    "\n",
    "        hits.append({\n",
    "            'title': meta.get('title', ''),\n",
    "            'description': doc_text,\n",
    "            'link': meta.get('link', ''),\n",
    "            'date_published': meta.get('date_published', '')\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(hits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e035a669-dca0-4127-bdf8-dfb31711d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trabajamos con LangChain\n",
    "# Modular pipeline: fetch → preparamos documentos → embed → almacenamos\n",
    "def step_fetch(rss_url=RPP_RSS_URL, max_items=MAX_ITEMS):\n",
    "    #Descargamos artículos RSS y la función te devuelve un DataFrame limpio.#\n",
    "    return fetch_rss_items(rss_url, max_items)\n",
    "def step_prepare_documents(df: pd.DataFrame):\n",
    "    docs_local = []  # Lista local docs\n",
    "    for idx, row in df.iterrows():\n",
    "        text = (row['title'] or '') + '\\n\\n' + (row['description'] or '')  # Combinar texto\n",
    "        if count_tokens_tiktoken(text) > CHUNK_TOKEN_TARGET:\n",
    "            text_chunks = chunk_text(text, chunk_size_chars=1500)  # Chunks si largo\n",
    "            for ci, c in enumerate(text_chunks):\n",
    "                docs_local.append({\n",
    "                    'id': f\"{idx}_chunk{ci}\",\n",
    "                    'text': c,\n",
    "                    'metadata': {\n",
    "                        'orig_index': int(idx),\n",
    "                        'chunk_id': ci,\n",
    "                        'title': row['title'],\n",
    "                        'link': row['link'],\n",
    "                        'date_published': row['date_published'],\n",
    "                    },\n",
    "                })\n",
    "        else:\n",
    "            docs_local.append({\n",
    "                'id': f\"{idx}\",\n",
    "                'text': text,\n",
    "                'metadata': {\n",
    "                    'orig_index': int(idx),\n",
    "                    'chunk_id': 0,\n",
    "                    'title': row['title'],\n",
    "                    'link': row['link'],\n",
    "                    'date_published': row['date_published'],\n",
    "                },\n",
    "            })\n",
    "    return docs_local  # Retornar docs preparados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43659a37-e681-4451-8cb4-9c23f26fc922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (0.4)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.39)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (3.11.10)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (2.11.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.37)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-community) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17bbdabe-3074-4b65-8e6c-032ab386028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_embed_and_upsert(\n",
    "    docs_local,\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    use_langchain_chroma=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Crea embeddings para los documentos y los inserta (upsert) en una base Chroma.\n",
    "    \n",
    "    Parámetros:\n",
    "    - docs_local: lista de documentos generada por step_prepare_documents().\n",
    "    - persist_directory: carpeta donde se guardarán los datos de Chroma.\n",
    "    - use_langchain_chroma: si True, usa la versión LangChain de Chroma.\n",
    "    \n",
    "    Retorna:\n",
    "    - collection (Chroma) o vectordb (LangChain Chroma) según el caso.\n",
    "    \"\"\"\n",
    "    # Cargamos modelo de embeddings\n",
    "    emb_model = EmbeddingModel()\n",
    "    emb_model.load()\n",
    "\n",
    "    texts = [d[\"text\"] for d in docs_local]\n",
    "    embeddings = emb_model.embed_texts(texts)\n",
    "\n",
    "    # Opción LangChain: usa su wrapper de Chroma\n",
    "    if use_langchain_chroma:\n",
    "        # --- Wrapper pequeño para usar sentence-transformers con LangChain's LCChroma ---\n",
    "        from langchain_community.vectorstores import Chroma as LCChroma\n",
    "        from langchain_core.documents import Document as LC_Document\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        import numpy as np\n",
    "\n",
    "        class STEmbeddingsWrapper:\n",
    "            \"\"\"\n",
    "            Wrapper que adapta sentence-transformers a la interfaz mínima\n",
    "            que LangChain/Chroma espera: embed_documents(list[str]) -> List[List[float]]\n",
    "            y embed_query(str) -> List[float]\n",
    "            \"\"\"\n",
    "            def __init__(self, model_name):\n",
    "                self.model = SentenceTransformer(model_name)\n",
    "\n",
    "            def embed_documents(self, texts: list) -> list:\n",
    "                embs = self.model.encode(texts, show_progress_bar=True)\n",
    "                return [emb.tolist() if hasattr(emb, \"tolist\") else list(np.array(emb)) for emb in embs]\n",
    "\n",
    "            def embed_query(self, text: str) -> list:\n",
    "                emb = self.model.encode([text], show_progress_bar=False)[0]\n",
    "                return emb.tolist() if hasattr(emb, \"tolist\") else list(np.array(emb))\n",
    "\n",
    "        # Instanciar wrapper\n",
    "        st_embedder = STEmbeddingsWrapper(model_name=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "        # LCChroma.from_documents espera un objeto 'embedding' con métodos embed_documents/embed_query\n",
    "        vectordb = LCChroma.from_documents(\n",
    "            documents=[LC_Document(page_content=d[\"text\"], metadata=d[\"metadata\"]) for d in docs_local],\n",
    "            embedding=st_embedder,\n",
    "            persist_directory=persist_directory,\n",
    "            collection_name=CHROMA_COLLECTION_NAME\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            vectordb.persist()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        return vectordb\n",
    "\n",
    "    # Opción Chroma nativa\n",
    "    else:\n",
    "        client, collection = init_chroma(persist_directory)\n",
    "        ids = [d[\"id\"] for d in docs_local]\n",
    "        metadatas = [d[\"metadata\"] for d in docs_local]\n",
    "        documents_texts = [d[\"text\"] for d in docs_local]\n",
    "\n",
    "        collection.upsert(\n",
    "            ids=ids,\n",
    "            embeddings=embeddings.tolist(),\n",
    "            metadatas=metadatas,\n",
    "            documents=documents_texts\n",
    "        )\n",
    "\n",
    "        # Chroma se guarda automáticamente si se usa persist_directory\n",
    "        return collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac9f29af-6e83-4d98-837e-1f275a9631d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Query wrapper usando LangChain vectorstore o raw Chroma client\n",
    "def query_pipeline(\n",
    "    query: str,\n",
    "    top_k: int = 5,\n",
    "    use_langchain_chroma: bool = False,\n",
    "    vectordb=None,\n",
    "    raw_collection=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Ejecuta una consulta semántica sobre la base de vectores (Chroma o LangChain-Chroma).\n",
    "    \n",
    "    Parámetros:\n",
    "    - query: texto de la búsqueda.\n",
    "    - top_k: número de resultados a retornar.\n",
    "    - use_langchain_chroma: True si se usa LCChroma, False si se usa Chroma nativo.\n",
    "    - vectordb: objeto LangChain-Chroma si use_langchain_chroma=True.\n",
    "    - raw_collection: colección nativa de Chroma si use_langchain_chroma=False.\n",
    "    \n",
    "    Retorna:\n",
    "    - DataFrame con columnas: title | description | link | date_published\n",
    "    \"\"\"\n",
    "\n",
    "    if use_langchain_chroma and vectordb is not None:\n",
    "        # 🔹 LangChain wrapper\n",
    "        docs = vectordb.similarity_search(query, k=top_k)\n",
    "        rows = []\n",
    "        for d in docs:\n",
    "            rows.append({\n",
    "                \"title\": d.metadata.get(\"title\"),\n",
    "                \"description\": d.page_content[:400],  # truncamos descripción\n",
    "                \"link\": d.metadata.get(\"link\"),\n",
    "                \"date_published\": d.metadata.get(\"date_published\")\n",
    "            })\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    elif raw_collection is not None:\n",
    "        # 🔹 Chroma nativo\n",
    "        emb_model = EmbeddingModel()\n",
    "        emb_model.load()\n",
    "        q_emb = emb_model.embed_texts([query])[0]\n",
    "        res = chroma_similarity_search(raw_collection, q_emb, top_k=top_k)\n",
    "        dfres = results_to_dataframe(res)\n",
    "        return dfres\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"No vector DB provided. Provide 'vectordb' (LangChain) or 'raw_collection' (Chroma client).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b66c6ab1-bd13-4720-a2da-7511f8ce58d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajoaq\\anaconda3\\envs\\task_1\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'rpp.pe'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "      <th>date_published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nicolás Maduro anuncia nuevos ejercicios milit...</td>\n",
       "      <td>Maduro sostuvo que a la medianoche de este jue...</td>\n",
       "      <td>https://rpp.pe/mundo/actualidad/nicolas-maduro...</td>\n",
       "      <td>2025-10-23T22:47:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Latin Billboard 2025: lista completa de nomina...</td>\n",
       "      <td>En esta edición, Bad Bunny encabeza las nomina...</td>\n",
       "      <td>https://rpp.pe/musica/internacional/latin-bill...</td>\n",
       "      <td>2025-10-23T22:45:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Universitario vs. Sporting Cristal hoy EN VIVO...</td>\n",
       "      <td>Sporting Cristal recibe a Universitario en un ...</td>\n",
       "      <td>https://rpp.pe/futbol/descentralizado/universi...</td>\n",
       "      <td>2025-10-23T22:45:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cristian Castro jugó fútbol con sus fans en Li...</td>\n",
       "      <td>¡Ya está en Lima! A pocas horas de su conciert...</td>\n",
       "      <td>https://rpp.pe/famosos/celebridades/cristian-c...</td>\n",
       "      <td>2025-10-23T21:42:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cronograma del octavo retiro de AFP 2025 sigue...</td>\n",
       "      <td>El desembolso se efectuará hasta en cuatro arm...</td>\n",
       "      <td>https://rpp.pe/economia/economia/octavo-retiro...</td>\n",
       "      <td>2025-10-23T22:40:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Nicolás Maduro anuncia nuevos ejercicios milit...   \n",
       "1  Latin Billboard 2025: lista completa de nomina...   \n",
       "2  Universitario vs. Sporting Cristal hoy EN VIVO...   \n",
       "3  Cristian Castro jugó fútbol con sus fans en Li...   \n",
       "4  Cronograma del octavo retiro de AFP 2025 sigue...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Maduro sostuvo que a la medianoche de este jue...   \n",
       "1  En esta edición, Bad Bunny encabeza las nomina...   \n",
       "2  Sporting Cristal recibe a Universitario en un ...   \n",
       "3  ¡Ya está en Lima! A pocas horas de su conciert...   \n",
       "4  El desembolso se efectuará hasta en cuatro arm...   \n",
       "\n",
       "                                                link       date_published  \n",
       "0  https://rpp.pe/mundo/actualidad/nicolas-maduro...  2025-10-23T22:47:59  \n",
       "1  https://rpp.pe/musica/internacional/latin-bill...  2025-10-23T22:45:15  \n",
       "2  https://rpp.pe/futbol/descentralizado/universi...  2025-10-23T22:45:08  \n",
       "3  https://rpp.pe/famosos/celebridades/cristian-c...  2025-10-23T21:42:51  \n",
       "4  https://rpp.pe/economia/economia/octavo-retiro...  2025-10-23T22:40:03  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacemos un ejemplo:\n",
    "\n",
    "df = step_fetch()\n",
    "print(len(df))\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ccb5028-343d-41cc-ae16-42d62254da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# Preparamos los documentos: combinamos titles + description y crea los textos listos para embeddings \n",
    "docs_local = step_prepare_documents(df)\n",
    "print(len(docs_local))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "179bcf48-5dd9-45df-a271-05d592d15c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.23s/it]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.09s/it]\n",
      "C:\\Users\\ajoaq\\AppData\\Local\\Temp\\ipykernel_4900\\781152508.py:61: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "#Creamos los embeddings y guardamos en Chroma: \n",
    "\n",
    "vectordb = step_embed_and_upsert(\n",
    "    docs_local,\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    use_langchain_chroma=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9391619f-189d-4446-ad6a-6f11ecfbe94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "      <th>date_published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Congreso otorga confianza al gabinete de Ernes...</td>\n",
       "      <td>Congreso otorga confianza al gabinete de Ernes...</td>\n",
       "      <td>https://rpp.pe/politica/congreso/congreso-otor...</td>\n",
       "      <td>2025-10-23T14:59:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rafael Vela: Proceso disciplinario contra José...</td>\n",
       "      <td>Rafael Vela: Proceso disciplinario contra José...</td>\n",
       "      <td>https://rpp.pe/politica/judiciales/rafael-vela...</td>\n",
       "      <td>2025-10-23T15:00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poder Judicial ratificó sentencia de cadena pe...</td>\n",
       "      <td>Poder Judicial ratificó sentencia de cadena pe...</td>\n",
       "      <td>https://rpp.pe/politica/judiciales/poder-judic...</td>\n",
       "      <td>2025-10-23T19:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poder Judicial ratificó sentencia de cadena pe...</td>\n",
       "      <td>Poder Judicial ratificó sentencia de cadena pe...</td>\n",
       "      <td>https://rpp.pe/politica/judiciales/poder-judic...</td>\n",
       "      <td>2025-10-23T19:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crimen en Carabayllo: asesinan a alférez de la...</td>\n",
       "      <td>Crimen en Carabayllo: asesinan a alférez de la...</td>\n",
       "      <td>https://rpp.pe/lima/policiales/crimen-a-caraba...</td>\n",
       "      <td>2025-10-23T12:55:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Congreso otorga confianza al gabinete de Ernes...   \n",
       "1  Rafael Vela: Proceso disciplinario contra José...   \n",
       "2  Poder Judicial ratificó sentencia de cadena pe...   \n",
       "3  Poder Judicial ratificó sentencia de cadena pe...   \n",
       "4  Crimen en Carabayllo: asesinan a alférez de la...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Congreso otorga confianza al gabinete de Ernes...   \n",
       "1  Rafael Vela: Proceso disciplinario contra José...   \n",
       "2  Poder Judicial ratificó sentencia de cadena pe...   \n",
       "3  Poder Judicial ratificó sentencia de cadena pe...   \n",
       "4  Crimen en Carabayllo: asesinan a alférez de la...   \n",
       "\n",
       "                                                link       date_published  \n",
       "0  https://rpp.pe/politica/congreso/congreso-otor...  2025-10-23T14:59:50  \n",
       "1  https://rpp.pe/politica/judiciales/rafael-vela...  2025-10-23T15:00:15  \n",
       "2  https://rpp.pe/politica/judiciales/poder-judic...  2025-10-23T19:00:55  \n",
       "3  https://rpp.pe/politica/judiciales/poder-judic...  2025-10-23T19:00:55  \n",
       "4  https://rpp.pe/lima/policiales/crimen-a-caraba...  2025-10-23T12:55:09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ejecutamos una busqueda para ver si funciona.. \n",
    "\n",
    "results_df = query_pipeline(\n",
    "    query=\"Últimas noticias de política\",\n",
    "    top_k=5,\n",
    "    use_langchain_chroma=True,\n",
    "    vectordb=vectordb\n",
    ")\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1367585-fb95-465a-9b77-5cea474afa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos outputs:\n",
    "# Limpiar datos\n",
    "df_clean = df.copy()\n",
    "df_clean['title'] = df_clean['title'].str.replace('\\n', ' ').str.replace('|', ' ')\n",
    "df_clean['description'] = df_clean['description'].str.replace('\\n', ' ').str.replace('|', ' ')\n",
    "df_clean['description'] = df_clean['description'].str[:200] + '...'  # Truncar a 200 caracteres\n",
    "\n",
    "results_df_clean = results_df.copy()\n",
    "results_df_clean['title'] = results_df_clean['title'].str.replace('\\n', ' ').str.replace('|', ' ')\n",
    "results_df_clean['description'] = results_df_clean['description'].str.replace('\\n', ' ').str.replace('|', ' ')\n",
    "results_df_clean['description'] = results_df_clean['description'].str[:200] + '...'  # Truncar a 200 caracteres\n",
    "\n",
    "# Guardar CSV con formato mejorado\n",
    "df_clean.to_csv(\n",
    "    \"rpp_articles_raw_clean.csv\",\n",
    "    index=False,\n",
    "    sep=\"|\",\n",
    "    encoding=\"utf-8-sig\",\n",
    "    quoting=csv.QUOTE_NONNUMERIC\n",
    ")\n",
    "\n",
    "\n",
    "results_df.to_csv(\n",
    "    \"rpp_query_results.csv\",\n",
    "    index=False,\n",
    "    sep=\"|\",                    # Usar '|' como separador\n",
    "    encoding=\"utf-8-sig\",       # Codificación compatible con Excel\n",
    "    quoting=csv.QUOTE_NONNUMERIC  # Encerrar campos de texto en comillas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cd1a7f-e5cf-4a53-93a9-7f58d1bdfb49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task_1",
   "language": "python",
   "name": "task_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
