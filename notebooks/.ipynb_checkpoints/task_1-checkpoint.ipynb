{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd3d70a8-4ef5-4be6-92aa-63192b8db1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipywidgets) (8.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.12 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: executing in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "#Primero importamos algunas librerias necesarias para el procesamiento de los c√≥digos:\n",
    "\n",
    "!pip install ipywidgets\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b739a2-9d0a-4f70-9859-58d99f6a1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seguimos... \n",
    "\n",
    "# Imports de ML/embeddings - deben estar instalados\n",
    "try:\n",
    " from sentence_transformers import SentenceTransformer # para generar embeddings \n",
    "except Exception as e:\n",
    " SentenceTransformer = None\n",
    "try:\n",
    " import tiktoken #para contar tokens\n",
    "except Exception:\n",
    " tiktoken = None\n",
    "try:\n",
    " import chromadb # para la base de datos vectorial \n",
    " from chromadb.config import Settings\n",
    " from chromadb.utils import embedding_functions #funciones de embeddings\n",
    "except Exception:\n",
    " chromadb = None\n",
    "# LangChain - conecta los pasos en un pipeline\n",
    "try:\n",
    " from langchain.schema import Document\n",
    " from langchain.embeddings import SentenceTransformerEmbeddings\n",
    " from langchain.vectorstores import Chroma\n",
    " from langchain.chains import SimpleSequentialChain, LLMChain\n",
    " from langchain.prompts import PromptTemplate\n",
    " from langchain.llms import OpenAI\n",
    "except Exception:\n",
    "\n",
    " pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab62e2e-cc86-4b34-91bf-d2dbf3a5e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuraci√≥n inicial: \n",
    "RPP_RSS_URL = \"https://rpp.pe/rss\"\n",
    "MAX_ITEMS = 50\n",
    "PERSIST_DIRECTORY = \"./chroma_rpp_db\"\n",
    "CHROMA_COLLECTION_NAME = \"rpp_news\"\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e338d480-29e3-4bc1-92d1-f9d989da4953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#Cargamos la data: Parseamos el feed RSS y extraemos hasta 50 (max items) entradas\n",
    "\n",
    "def fetch_rss_items(rss_url: str, max_items: int = 50):\n",
    "    try:\n",
    "        # ‚öôÔ∏è Usa requests para obtener el XML ignorando SSL\n",
    "        response = requests.get(rss_url, verify=False, timeout=10)\n",
    "        response.raise_for_status()  # error si el request falla\n",
    "        feed = feedparser.parse(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al descargar o parsear feed: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    entries = feed.get(\"entries\", [])[:max_items]\n",
    "    records = [] #lista para almacenar los datos\n",
    "    for e in entries:\n",
    "        title = e.get(\"title\", \"\") #t√≠tulo\n",
    "        description = e.get(\"description\", \"\") #descripci√≥n\n",
    "        link = e.get(\"link\", \"\") #enlace\n",
    "        published = e.get(\"published\", \"\") #fecha de publicaci√≥n\n",
    "        #Normalizamos la fecha si esta en formato parsed\n",
    "        try:\n",
    "            published_parsed = e.get(\"published_parsed\")\n",
    "            if published_parsed:\n",
    "                published = datetime(*published_parsed[:6]).isoformat()\n",
    "        except Exception:\n",
    "            pass\n",
    "        records.append({\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "            \"link\": link,\n",
    "            \"date_published\": published,\n",
    "        })\n",
    "    return pd.DataFrame(records) #convertimos a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c1cfe18-91d3-4823-8028-ee54a942ab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajoaq\\anaconda3\\envs\\task_1\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'rpp.pe'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 50 items\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "      <th>date_published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nicol√°s Maduro anuncia nuevos ejercicios milit...</td>\n",
       "      <td>Maduro sostuvo que a la medianoche de este jue...</td>\n",
       "      <td>https://rpp.pe/mundo/actualidad/nicolas-maduro...</td>\n",
       "      <td>2025-10-23T22:47:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Latin Billboard 2025: lista completa de nomina...</td>\n",
       "      <td>En esta edici√≥n, Bad Bunny encabeza las nomina...</td>\n",
       "      <td>https://rpp.pe/musica/internacional/latin-bill...</td>\n",
       "      <td>2025-10-23T22:45:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Universitario vs. Sporting Cristal hoy EN VIVO...</td>\n",
       "      <td>Sporting Cristal recibe a Universitario en un ...</td>\n",
       "      <td>https://rpp.pe/futbol/descentralizado/universi...</td>\n",
       "      <td>2025-10-23T22:45:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cristian Castro jug√≥ f√∫tbol con sus fans en Li...</td>\n",
       "      <td>¬°Ya est√° en Lima! A pocas horas de su conciert...</td>\n",
       "      <td>https://rpp.pe/famosos/celebridades/cristian-c...</td>\n",
       "      <td>2025-10-23T21:42:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cronograma del octavo retiro de AFP 2025 sigue...</td>\n",
       "      <td>El desembolso se efectuar√° hasta en cuatro arm...</td>\n",
       "      <td>https://rpp.pe/economia/economia/octavo-retiro...</td>\n",
       "      <td>2025-10-23T22:40:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Nicol√°s Maduro anuncia nuevos ejercicios milit...   \n",
       "1  Latin Billboard 2025: lista completa de nomina...   \n",
       "2  Universitario vs. Sporting Cristal hoy EN VIVO...   \n",
       "3  Cristian Castro jug√≥ f√∫tbol con sus fans en Li...   \n",
       "4  Cronograma del octavo retiro de AFP 2025 sigue...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Maduro sostuvo que a la medianoche de este jue...   \n",
       "1  En esta edici√≥n, Bad Bunny encabeza las nomina...   \n",
       "2  Sporting Cristal recibe a Universitario en un ...   \n",
       "3  ¬°Ya est√° en Lima! A pocas horas de su conciert...   \n",
       "4  El desembolso se efectuar√° hasta en cuatro arm...   \n",
       "\n",
       "                                                link       date_published  \n",
       "0  https://rpp.pe/mundo/actualidad/nicolas-maduro...  2025-10-23T22:47:59  \n",
       "1  https://rpp.pe/musica/internacional/latin-bill...  2025-10-23T22:45:15  \n",
       "2  https://rpp.pe/futbol/descentralizado/universi...  2025-10-23T22:45:08  \n",
       "3  https://rpp.pe/famosos/celebridades/cristian-c...  2025-10-23T21:42:51  \n",
       "4  https://rpp.pe/economia/economia/octavo-retiro...  2025-10-23T22:40:03  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RPP_RSS_URL = \"https://rpp.pe/rss\"\n",
    "df = fetch_rss_items(RPP_RSS_URL, 50)\n",
    "print(f\"Fetched {len(df)} items\")\n",
    "df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089ab53e-78f8-4027-b59f-f023e97bd3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# TOKENIZATION: un articulo de ejemplo utilizando tiktoken\n",
    "def count_tokens_tiktoken(text: str, model_name: str = \"gpt-4o-mini\") -> int:\n",
    "    \"\"\"\n",
    "    Use tiktoken if available. Provide a fallback token estimation (approx 4 chars/token).\n",
    "    \"\"\"\n",
    "    if tiktoken is None:\n",
    "        return max(1, math.ceil(len(text) / 4))\n",
    "    try:\n",
    "        enc = tiktoken.encoding_for_model(model_name)\n",
    "    except Exception:\n",
    "        try:\n",
    "            enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        except Exception:\n",
    "            return max(1, math.ceil(len(text) / 4))\n",
    "    return len(enc.encode(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a40d95cf-3685-41c4-9ef9-f2906792c24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokens: 70\n"
     ]
    }
   ],
   "source": [
    "# Creamos un \"sample\" de texto del primer item RSS\n",
    "sample_text = (df.loc[0, \"title\"] or \"\") + \"\\n\\n\" + (df.loc[0, \"description\"] or \"\")\n",
    "\n",
    "num_tokens = count_tokens_tiktoken(sample_text)\n",
    "print(\"Sample tokens:\", num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed0df50e-f01e-4de4-9830-4a1fb7d56640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needs chunking? False\n"
     ]
    }
   ],
   "source": [
    "# Decidimos si el chinking se necesita\n",
    "MODEL_TOKEN_LIMIT = 4096\n",
    "CHUNK_TOKEN_TARGET = 1000  # target de tokens por chunk\n",
    "needs_chunking = num_tokens > CHUNK_TOKEN_TARGET\n",
    "print(\"Needs chunking?\", needs_chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff7f906-0738-4f88-8d1d-2759f5019c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking helper (naive words-based ‚Äî can replace with tiktoken-based chunker)\n",
    "def chunk_text(text: str, chunk_size_chars: int = 2000):\n",
    "    \"\"\"Naive chunk by characters preserving whole words.\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    cur = []\n",
    "    cur_len = 0\n",
    "    for w in words:\n",
    "        if cur_len + len(w) + 1 > chunk_size_chars:\n",
    "            chunks.append(\" \".join(cur))\n",
    "            cur = [w]\n",
    "            cur_len = len(w) + 1\n",
    "        else:\n",
    "            cur.append(w)\n",
    "            cur_len += len(w) + 1\n",
    "    if cur:\n",
    "        chunks.append(\" \".join(cur))\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Example chunk preview\n",
    "if needs_chunking:\n",
    "    chunks = chunk_text(sample_text, chunk_size_chars=1500)\n",
    "    print(\"Chunks created:\", len(chunks))\n",
    "    for i, c in enumerate(chunks[:2]):\n",
    "        print(i, \"len chars:\", len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ac1b4d3-70ca-48e3-9b21-90fd07d3a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "\n",
    "# EMBEDDING: Utilizamos SentenceTransformers\n",
    "def load_sentence_transformer(model_name: str = EMBEDDING_MODEL_NAME):\n",
    "    #Cargamos el modelo SentenceTransformers\n",
    "    if SentenceTransformer is None:\n",
    "        raise ImportError(\"sentence-transformers not installed. Install from requirements.txt\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fcbdcda-46b5-4025-bde7-3e9625492d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings model wrapper\n",
    "class EmbeddingModel:\n",
    "    def __init__(self, model_name=EMBEDDING_MODEL_NAME):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "\n",
    "    def load(self):\n",
    "        self.model = load_sentence_transformer(self.model_name)\n",
    "\n",
    "    def embed_texts(self, texts: list) -> np.ndarray:\n",
    "        if self.model is None:\n",
    "            self.load()\n",
    "        return np.array(self.model.encode(texts, show_progress_bar=True)) #genera embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2513e22-84c4-4737-99c9-2e0a7501d125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de documentos para el embed: 50\n",
      "Ejemplo de doc.: {'id': '0', 'text': 'Nicol√°s Maduro anuncia nuevos ejercicios militares en las costas de Venezuela por 72 horas\\n\\nMaduro sostuvo que a la medianoche de este jueves llam√≥ a \"quienes ten√≠a que llamar\" y dio la orden de activar todos los equipos militares \"de inmediato\" para la defensa de los \"puntos de acci√≥n\" en toda la costa de Venezuela.', 'metadata': {'orig_index': 0, 'chunk_id': 0, 'title': 'Nicol√°s Maduro anuncia nuevos ejercicios militares en las costas de Venezuela por 72 horas', 'link': 'https://rpp.pe/mundo/actualidad/nicolas-maduro-anuncia-nuevos-ejercicios-militares-en-las-costas-de-venezuela-por-72-horas-noticia-1660705', 'date_published': '2025-10-23T22:47:59'}}\n"
     ]
    }
   ],
   "source": [
    "# Preparamos documentos para el embed: combinamos t√≠tulo + descripci√≥n, chunking si es necesario\n",
    "docs = []\n",
    "for idx, row in df.iterrows():\n",
    "    text = (row[\"title\"] or \"\") + \"\\n\\n\" + (row[\"description\"] or \"\")\n",
    "    if count_tokens_tiktoken(text) > CHUNK_TOKEN_TARGET:\n",
    "        text_chunks = chunk_text(text, chunk_size_chars=1500)\n",
    "        for ci, c in enumerate(text_chunks):\n",
    "            docs.append({\n",
    "                \"id\": f\"{idx}_chunk{ci}\",\n",
    "                \"text\": c,\n",
    "                \"metadata\": {\n",
    "                    \"orig_index\": int(idx),\n",
    "                    \"chunk_id\": ci,\n",
    "                    \"title\": row[\"title\"],\n",
    "                    \"link\": row[\"link\"],\n",
    "                    \"date_published\": row[\"date_published\"],\n",
    "                },\n",
    "            })\n",
    "    else:\n",
    "        docs.append({\n",
    "            \"id\": f\"{idx}\",\n",
    "            \"text\": text,\n",
    "            \"metadata\": {\n",
    "                \"orig_index\": int(idx),\n",
    "                \"chunk_id\": 0,\n",
    "                \"title\": row[\"title\"],\n",
    "                \"link\": row[\"link\"],\n",
    "                \"date_published\": row[\"date_published\"],\n",
    "            },\n",
    "        })\n",
    "\n",
    "print(\"Total de documentos para el embed:\", len(docs))\n",
    "print(\"Ejemplo de doc.:\", docs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97211464-698d-4a33-bf38-9d6fe03a4828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (50, 384)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "emb = EmbeddingModel() #Creamos instancia del modelo de embeddings\n",
    "\n",
    "# Para demo/testeo:\n",
    "embeddings = np.random.randn(len(docs), 384).astype(np.float32)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa48fc1e-d7b3-4612-9b92-1deba4334c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos collecci√≥n Chroma:\n",
    "def init_chroma(persist_directory: str = PERSIST_DIRECTORY, embedding_function=None):\n",
    "    \n",
    "    # Verificar instalaci√≥n de chromadb\n",
    "    try:\n",
    "        import chromadb\n",
    "        from chromadb.config import Settings\n",
    "    except ImportError:\n",
    "        raise ImportError(\"chromadb not installed. Please install it via 'pip install chromadb'.\")\n",
    "\n",
    "    # Creamos cliente con configuraci√≥n\n",
    "    client = chromadb.Client(\n",
    "        Settings(\n",
    "            chroma_db_impl=\"duckdb+parquet\",\n",
    "            persist_directory=persist_directory\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Creamos o recuperamos colecci√≥n\n",
    "    collection = client.get_or_create_collection(\n",
    "        name=CHROMA_COLLECTION_NAME,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "\n",
    "    return client, collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2279a30b-c14e-4108-a0a0-15b0ecfc6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados Query: ejemplo de busqueda por similitud\n",
    "def chroma_similarity_search(collection, query_embedding, top_k=5):\n",
    "    \"\"\"\n",
    "    Ejecuta una b√∫squeda de similitud en una colecci√≥n de Chroma.\n",
    "    Retorna los resultados m√°s similares seg√∫n el embedding de consulta.\n",
    "    \"\"\"\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding.tolist()],\n",
    "        n_results=top_k,\n",
    "        include=['metadatas', 'documents', 'distances']\n",
    "    )\n",
    "    return results\n",
    "\n",
    "\n",
    "# Convertimos resultados de Chroma a DataFrame legible:\n",
    "def results_to_dataframe(results):\n",
    "    \"\"\"\n",
    "    Convierte los resultados de una b√∫squeda en Chroma a un DataFrame\n",
    "    con columnas: title, description, link, date_published.\n",
    "    \"\"\"\n",
    "    hits = []\n",
    "\n",
    "    # results ... estructura: dict con 'ids', 'documents', 'metadatas', 'distances' ‚Äî listas por query\n",
    "    if not results or not results.get('ids'):\n",
    "        return pd.DataFrame(columns=['title', 'description', 'link', 'date_published'])\n",
    "\n",
    "    for i in range(len(results['ids'][0])):\n",
    "        meta = results['metadatas'][0][i]\n",
    "        doc_text = results['documents'][0][i]\n",
    "\n",
    "        hits.append({\n",
    "            'title': meta.get('title', ''),\n",
    "            'description': doc_text,\n",
    "            'link': meta.get('link', ''),\n",
    "            'date_published': meta.get('date_published', '')\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(hits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e035a669-dca0-4127-bdf8-dfb31711d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trabajamos con LangChain\n",
    "# Modular pipeline: fetch ‚Üí preparamos documentos ‚Üí embed ‚Üí almacenamos\n",
    "def step_fetch(rss_url=RPP_RSS_URL, max_items=MAX_ITEMS):\n",
    "    #Descargamos art√≠culos RSS y la funci√≥n te devuelve un DataFrame limpio.#\n",
    "    return fetch_rss_items(rss_url, max_items)\n",
    "def step_prepare_documents(df: pd.DataFrame):\n",
    "    docs_local = []  # Lista local docs\n",
    "    for idx, row in df.iterrows():\n",
    "        text = (row['title'] or '') + '\\n\\n' + (row['description'] or '')  # Combinar texto\n",
    "        if count_tokens_tiktoken(text) > CHUNK_TOKEN_TARGET:\n",
    "            text_chunks = chunk_text(text, chunk_size_chars=1500)  # Chunks si largo\n",
    "            for ci, c in enumerate(text_chunks):\n",
    "                docs_local.append({\n",
    "                    'id': f\"{idx}_chunk{ci}\",\n",
    "                    'text': c,\n",
    "                    'metadata': {\n",
    "                        'orig_index': int(idx),\n",
    "                        'chunk_id': ci,\n",
    "                        'title': row['title'],\n",
    "                        'link': row['link'],\n",
    "                        'date_published': row['date_published'],\n",
    "                    },\n",
    "                })\n",
    "        else:\n",
    "            docs_local.append({\n",
    "                'id': f\"{idx}\",\n",
    "                'text': text,\n",
    "                'metadata': {\n",
    "                    'orig_index': int(idx),\n",
    "                    'chunk_id': 0,\n",
    "                    'title': row['title'],\n",
    "                    'link': row['link'],\n",
    "                    'date_published': row['date_published'],\n",
    "                },\n",
    "            })\n",
    "    return docs_local  # Retornar docs preparados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43659a37-e681-4451-8cb4-9c23f26fc922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (0.4)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.39)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (3.11.10)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (2.11.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.37)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-community) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-community) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17bbdabe-3074-4b65-8e6c-032ab386028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_embed_and_upsert(\n",
    "    docs_local,\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    use_langchain_chroma=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Crea embeddings para los documentos y los inserta (upsert) en una base Chroma.\n",
    "    \n",
    "    Par√°metros:\n",
    "    - docs_local: lista de documentos generada por step_prepare_documents().\n",
    "    - persist_directory: carpeta donde se guardar√°n los datos de Chroma.\n",
    "    - use_langchain_chroma: si True, usa la versi√≥n LangChain de Chroma.\n",
    "    \n",
    "    Retorna:\n",
    "    - collection (Chroma) o vectordb (LangChain Chroma) seg√∫n el caso.\n",
    "    \"\"\"\n",
    "    # Cargamos modelo de embeddings\n",
    "    emb_model = EmbeddingModel()\n",
    "    emb_model.load()\n",
    "\n",
    "    texts = [d[\"text\"] for d in docs_local]\n",
    "    embeddings = emb_model.embed_texts(texts)\n",
    "\n",
    "    # Opci√≥n LangChain: usa su wrapper de Chroma\n",
    "    if use_langchain_chroma:\n",
    "        # --- Wrapper peque√±o para usar sentence-transformers con LangChain's LCChroma ---\n",
    "        from langchain_community.vectorstores import Chroma as LCChroma\n",
    "        from langchain_core.documents import Document as LC_Document\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        import numpy as np\n",
    "\n",
    "        class STEmbeddingsWrapper:\n",
    "            \"\"\"\n",
    "            Wrapper que adapta sentence-transformers a la interfaz m√≠nima\n",
    "            que LangChain/Chroma espera: embed_documents(list[str]) -> List[List[float]]\n",
    "            y embed_query(str) -> List[float]\n",
    "            \"\"\"\n",
    "            def __init__(self, model_name):\n",
    "                self.model = SentenceTransformer(model_name)\n",
    "\n",
    "            def embed_documents(self, texts: list) -> list:\n",
    "                embs = self.model.encode(texts, show_progress_bar=True)\n",
    "                return [emb.tolist() if hasattr(emb, \"tolist\") else list(np.array(emb)) for emb in embs]\n",
    "\n",
    "            def embed_query(self, text: str) -> list:\n",
    "                emb = self.model.encode([text], show_progress_bar=False)[0]\n",
    "                return emb.tolist() if hasattr(emb, \"tolist\") else list(np.array(emb))\n",
    "\n",
    "        # Instanciar wrapper\n",
    "        st_embedder = STEmbeddingsWrapper(model_name=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "        # LCChroma.from_documents espera un objeto 'embedding' con m√©todos embed_documents/embed_query\n",
    "        vectordb = LCChroma.from_documents(\n",
    "            documents=[LC_Document(page_content=d[\"text\"], metadata=d[\"metadata\"]) for d in docs_local],\n",
    "            embedding=st_embedder,\n",
    "            persist_directory=persist_directory,\n",
    "            collection_name=CHROMA_COLLECTION_NAME\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            vectordb.persist()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        return vectordb\n",
    "\n",
    "    # Opci√≥n Chroma nativa\n",
    "    else:\n",
    "        client, collection = init_chroma(persist_directory)\n",
    "        ids = [d[\"id\"] for d in docs_local]\n",
    "        metadatas = [d[\"metadata\"] for d in docs_local]\n",
    "        documents_texts = [d[\"text\"] for d in docs_local]\n",
    "\n",
    "        collection.upsert(\n",
    "            ids=ids,\n",
    "            embeddings=embeddings.tolist(),\n",
    "            metadatas=metadatas,\n",
    "            documents=documents_texts\n",
    "        )\n",
    "\n",
    "        # Chroma se guarda autom√°ticamente si se usa persist_directory\n",
    "        return collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac9f29af-6e83-4d98-837e-1f275a9631d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Query wrapper usando LangChain vectorstore o raw Chroma client\n",
    "def query_pipeline(\n",
    "    query: str,\n",
    "    top_k: int = 5,\n",
    "    use_langchain_chroma: bool = False,\n",
    "    vectordb=None,\n",
    "    raw_collection=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Ejecuta una consulta sem√°ntica sobre la base de vectores (Chroma o LangChain-Chroma).\n",
    "    \n",
    "    Par√°metros:\n",
    "    - query: texto de la b√∫squeda.\n",
    "    - top_k: n√∫mero de resultados a retornar.\n",
    "    - use_langchain_chroma: True si se usa LCChroma, False si se usa Chroma nativo.\n",
    "    - vectordb: objeto LangChain-Chroma si use_langchain_chroma=True.\n",
    "    - raw_collection: colecci√≥n nativa de Chroma si use_langchain_chroma=False.\n",
    "    \n",
    "    Retorna:\n",
    "    - DataFrame con columnas: title | description | link | date_published\n",
    "    \"\"\"\n",
    "\n",
    "    if use_langchain_chroma and vectordb is not None:\n",
    "        # üîπ LangChain wrapper\n",
    "        docs = vectordb.similarity_search(query, k=top_k)\n",
    "        rows = []\n",
    "        for d in docs:\n",
    "            rows.append({\n",
    "                \"title\": d.metadata.get(\"title\"),\n",
    "                \"description\": d.page_content[:400],  # truncamos descripci√≥n\n",
    "                \"link\": d.metadata.get(\"link\"),\n",
    "                \"date_published\": d.metadata.get(\"date_published\")\n",
    "            })\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    elif raw_collection is not None:\n",
    "        # üîπ Chroma nativo\n",
    "        emb_model = EmbeddingModel()\n",
    "        emb_model.load()\n",
    "        q_emb = emb_model.embed_texts([query])[0]\n",
    "        res = chroma_similarity_search(raw_collection, q_emb, top_k=top_k)\n",
    "        dfres = results_to_dataframe(res)\n",
    "        return dfres\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"No vector DB provided. Provide 'vectordb' (LangChain) or 'raw_collection' (Chroma client).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b66c6ab1-bd13-4720-a2da-7511f8ce58d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajoaq\\anaconda3\\envs\\task_1\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'rpp.pe'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "      <th>date_published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nicol√°s Maduro anuncia nuevos ejercicios milit...</td>\n",
       "      <td>Maduro sostuvo que a la medianoche de este jue...</td>\n",
       "      <td>https://rpp.pe/mundo/actualidad/nicolas-maduro...</td>\n",
       "      <td>2025-10-23T22:47:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Latin Billboard 2025: lista completa de nomina...</td>\n",
       "      <td>En esta edici√≥n, Bad Bunny encabeza las nomina...</td>\n",
       "      <td>https://rpp.pe/musica/internacional/latin-bill...</td>\n",
       "      <td>2025-10-23T22:45:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Universitario vs. Sporting Cristal hoy EN VIVO...</td>\n",
       "      <td>Sporting Cristal recibe a Universitario en un ...</td>\n",
       "      <td>https://rpp.pe/futbol/descentralizado/universi...</td>\n",
       "      <td>2025-10-23T22:45:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cristian Castro jug√≥ f√∫tbol con sus fans en Li...</td>\n",
       "      <td>¬°Ya est√° en Lima! A pocas horas de su conciert...</td>\n",
       "      <td>https://rpp.pe/famosos/celebridades/cristian-c...</td>\n",
       "      <td>2025-10-23T21:42:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cronograma del octavo retiro de AFP 2025 sigue...</td>\n",
       "      <td>El desembolso se efectuar√° hasta en cuatro arm...</td>\n",
       "      <td>https://rpp.pe/economia/economia/octavo-retiro...</td>\n",
       "      <td>2025-10-23T22:40:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Nicol√°s Maduro anuncia nuevos ejercicios milit...   \n",
       "1  Latin Billboard 2025: lista completa de nomina...   \n",
       "2  Universitario vs. Sporting Cristal hoy EN VIVO...   \n",
       "3  Cristian Castro jug√≥ f√∫tbol con sus fans en Li...   \n",
       "4  Cronograma del octavo retiro de AFP 2025 sigue...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Maduro sostuvo que a la medianoche de este jue...   \n",
       "1  En esta edici√≥n, Bad Bunny encabeza las nomina...   \n",
       "2  Sporting Cristal recibe a Universitario en un ...   \n",
       "3  ¬°Ya est√° en Lima! A pocas horas de su conciert...   \n",
       "4  El desembolso se efectuar√° hasta en cuatro arm...   \n",
       "\n",
       "                                                link       date_published  \n",
       "0  https://rpp.pe/mundo/actualidad/nicolas-maduro...  2025-10-23T22:47:59  \n",
       "1  https://rpp.pe/musica/internacional/latin-bill...  2025-10-23T22:45:15  \n",
       "2  https://rpp.pe/futbol/descentralizado/universi...  2025-10-23T22:45:08  \n",
       "3  https://rpp.pe/famosos/celebridades/cristian-c...  2025-10-23T21:42:51  \n",
       "4  https://rpp.pe/economia/economia/octavo-retiro...  2025-10-23T22:40:03  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacemos un ejemplo:\n",
    "\n",
    "df = step_fetch()\n",
    "print(len(df))\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ccb5028-343d-41cc-ae16-42d62254da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# Preparamos los documentos: combinamos titles + description y crea los textos listos para embeddings \n",
    "docs_local = step_prepare_documents(df)\n",
    "print(len(docs_local))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "179bcf48-5dd9-45df-a271-05d592d15c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.23s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.09s/it]\n",
      "C:\\Users\\ajoaq\\AppData\\Local\\Temp\\ipykernel_4900\\781152508.py:61: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "#Creamos los embeddings y guardamos en Chroma: \n",
    "\n",
    "vectordb = step_embed_and_upsert(\n",
    "    docs_local,\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    use_langchain_chroma=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9391619f-189d-4446-ad6a-6f11ecfbe94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "      <th>date_published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Congreso otorga confianza al gabinete de Ernes...</td>\n",
       "      <td>Congreso otorga confianza al gabinete de Ernes...</td>\n",
       "      <td>https://rpp.pe/politica/congreso/congreso-otor...</td>\n",
       "      <td>2025-10-23T14:59:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rafael Vela: Proceso disciplinario contra Jos√©...</td>\n",
       "      <td>Rafael Vela: Proceso disciplinario contra Jos√©...</td>\n",
       "      <td>https://rpp.pe/politica/judiciales/rafael-vela...</td>\n",
       "      <td>2025-10-23T15:00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poder Judicial ratific√≥ sentencia de cadena pe...</td>\n",
       "      <td>Poder Judicial ratific√≥ sentencia de cadena pe...</td>\n",
       "      <td>https://rpp.pe/politica/judiciales/poder-judic...</td>\n",
       "      <td>2025-10-23T19:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poder Judicial ratific√≥ sentencia de cadena pe...</td>\n",
       "      <td>Poder Judicial ratific√≥ sentencia de cadena pe...</td>\n",
       "      <td>https://rpp.pe/politica/judiciales/poder-judic...</td>\n",
       "      <td>2025-10-23T19:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crimen en Carabayllo: asesinan a alf√©rez de la...</td>\n",
       "      <td>Crimen en Carabayllo: asesinan a alf√©rez de la...</td>\n",
       "      <td>https://rpp.pe/lima/policiales/crimen-a-caraba...</td>\n",
       "      <td>2025-10-23T12:55:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Congreso otorga confianza al gabinete de Ernes...   \n",
       "1  Rafael Vela: Proceso disciplinario contra Jos√©...   \n",
       "2  Poder Judicial ratific√≥ sentencia de cadena pe...   \n",
       "3  Poder Judicial ratific√≥ sentencia de cadena pe...   \n",
       "4  Crimen en Carabayllo: asesinan a alf√©rez de la...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Congreso otorga confianza al gabinete de Ernes...   \n",
       "1  Rafael Vela: Proceso disciplinario contra Jos√©...   \n",
       "2  Poder Judicial ratific√≥ sentencia de cadena pe...   \n",
       "3  Poder Judicial ratific√≥ sentencia de cadena pe...   \n",
       "4  Crimen en Carabayllo: asesinan a alf√©rez de la...   \n",
       "\n",
       "                                                link       date_published  \n",
       "0  https://rpp.pe/politica/congreso/congreso-otor...  2025-10-23T14:59:50  \n",
       "1  https://rpp.pe/politica/judiciales/rafael-vela...  2025-10-23T15:00:15  \n",
       "2  https://rpp.pe/politica/judiciales/poder-judic...  2025-10-23T19:00:55  \n",
       "3  https://rpp.pe/politica/judiciales/poder-judic...  2025-10-23T19:00:55  \n",
       "4  https://rpp.pe/lima/policiales/crimen-a-caraba...  2025-10-23T12:55:09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ejecutamos una busqueda para ver si funciona.. \n",
    "\n",
    "results_df = query_pipeline(\n",
    "    query=\"√öltimas noticias de pol√≠tica\",\n",
    "    top_k=5,\n",
    "    use_langchain_chroma=True,\n",
    "    vectordb=vectordb\n",
    ")\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1367585-fb95-465a-9b77-5cea474afa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos outputs:\n",
    "# Limpiar datos\n",
    "df_clean = df.copy()\n",
    "df_clean['title'] = df_clean['title'].str.replace('\\n', ' ').str.replace('|', ' ')\n",
    "df_clean['description'] = df_clean['description'].str.replace('\\n', ' ').str.replace('|', ' ')\n",
    "df_clean['description'] = df_clean['description'].str[:200] + '...'  # Truncar a 200 caracteres\n",
    "\n",
    "results_df_clean = results_df.copy()\n",
    "results_df_clean['title'] = results_df_clean['title'].str.replace('\\n', ' ').str.replace('|', ' ')\n",
    "results_df_clean['description'] = results_df_clean['description'].str.replace('\\n', ' ').str.replace('|', ' ')\n",
    "results_df_clean['description'] = results_df_clean['description'].str[:200] + '...'  # Truncar a 200 caracteres\n",
    "\n",
    "# Guardar CSV con formato mejorado\n",
    "df_clean.to_csv(\n",
    "    \"rpp_articles_raw_clean.csv\",\n",
    "    index=False,\n",
    "    sep=\"|\",\n",
    "    encoding=\"utf-8-sig\",\n",
    "    quoting=csv.QUOTE_NONNUMERIC\n",
    ")\n",
    "\n",
    "\n",
    "results_df.to_csv(\n",
    "    \"rpp_query_results.csv\",\n",
    "    index=False,\n",
    "    sep=\"|\",                    # Usar '|' como separador\n",
    "    encoding=\"utf-8-sig\",       # Codificaci√≥n compatible con Excel\n",
    "    quoting=csv.QUOTE_NONNUMERIC  # Encerrar campos de texto en comillas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cd1a7f-e5cf-4a53-93a9-7f58d1bdfb49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task_1",
   "language": "python",
   "name": "task_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
