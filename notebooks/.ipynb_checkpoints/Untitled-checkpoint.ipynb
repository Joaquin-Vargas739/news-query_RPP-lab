{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd3d70a8-4ef5-4be6-92aa-63192b8db1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipywidgets) (8.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.12 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: executing in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\ajoaq\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "#Primero importamos algunas librerias: \n",
    "\n",
    "!pip install ipywidgets\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22b739a2-9d0a-4f70-9859-58d99f6a1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seguimos... \n",
    "\n",
    "# Optional ML/embedding imports - these must be installed\n",
    "try:\n",
    " from sentence_transformers import SentenceTransformer\n",
    "except Exception as e:\n",
    " SentenceTransformer = None\n",
    "try:\n",
    " import tiktoken\n",
    "except Exception:\n",
    " tiktoken = None\n",
    "try:\n",
    " import chromadb\n",
    " from chromadb.config import Settings\n",
    " from chromadb.utils import embedding_functions\n",
    "except Exception:\n",
    " chromadb = None\n",
    "# LangChain\n",
    "try:\n",
    " from langchain.schema import Document\n",
    " from langchain.embeddings import SentenceTransformerEmbeddings\n",
    " from langchain.vectorstores import Chroma\n",
    " from langchain.chains import SimpleSequentialChain, LLMChain\n",
    " from langchain.prompts import PromptTemplate\n",
    " from langchain.llms import OpenAI\n",
    "except Exception:\n",
    "# We'll still provide the functions; user should install langchain to use them.\n",
    " pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eab62e2e-cc86-4b34-91bf-d2dbf3a5e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuración inicial: \n",
    "RPP_RSS_URL = \"https://rpp.pe/rss\"\n",
    "MAX_ITEMS = 50\n",
    "PERSIST_DIRECTORY = \"./chroma_rpp_db\"\n",
    "CHROMA_COLLECTION_NAME = \"rpp_news\"\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e338d480-29e3-4bc1-92d1-f9d989da4953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_rss_items(rss_url: str, max_items: int = 50):\n",
    "    try:\n",
    "        # ⚙️ Usa requests para obtener el XML ignorando SSL\n",
    "        response = requests.get(rss_url, verify=False, timeout=10)\n",
    "        response.raise_for_status()  # error si el request falla\n",
    "        feed = feedparser.parse(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al descargar o parsear feed: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    entries = feed.get(\"entries\", [])[:max_items]\n",
    "    records = []\n",
    "    for e in entries:\n",
    "        title = e.get(\"title\", \"\")\n",
    "        description = e.get(\"description\", \"\")\n",
    "        link = e.get(\"link\", \"\")\n",
    "        published = e.get(\"published\", \"\")\n",
    "        try:\n",
    "            published_parsed = e.get(\"published_parsed\")\n",
    "            if published_parsed:\n",
    "                published = datetime(*published_parsed[:6]).isoformat()\n",
    "        except Exception:\n",
    "            pass\n",
    "        records.append({\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "            \"link\": link,\n",
    "            \"date_published\": published,\n",
    "        })\n",
    "    return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c1cfe18-91d3-4823-8028-ee54a942ab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajoaq\\anaconda3\\envs\\task_1\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'rpp.pe'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 50 items\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "      <th>date_published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cúal fue el último temblor en México hoy 22 de...</td>\n",
       "      <td>Cuál es el ultimo temblor en México y CDMX reg...</td>\n",
       "      <td>https://rpp.pe/mundo/mexico/cual-fue-el-ultimo...</td>\n",
       "      <td>2025-10-22T11:42:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Temblor en Perú, hoy 22 de octubre: magnitud y...</td>\n",
       "      <td>Actualización EN VIVO del último sismo en Perú...</td>\n",
       "      <td>https://rpp.pe/lima/desastres-naturales/temblo...</td>\n",
       "      <td>2025-10-22T07:18:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pleno del Congreso otorga el voto de confianza...</td>\n",
       "      <td>Con 79 votos a favor, 15 en contra y 5 abstenc...</td>\n",
       "      <td>https://rpp.pe/politica/congreso/ernesto-alvar...</td>\n",
       "      <td>2025-10-23T01:28:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tabla de posiciones de la Champions League 202...</td>\n",
       "      <td>Conoce los resultados y la tabla de posiciones...</td>\n",
       "      <td>https://rpp.pe/futbol/champions-league/tabla-d...</td>\n",
       "      <td>2025-10-23T01:55:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EE.UU. sanciona a las dos principales petroler...</td>\n",
       "      <td>Las empresas Rosneft y Lukoil están especializ...</td>\n",
       "      <td>https://rpp.pe/mundo/actualidad/eeuu-sanciona-...</td>\n",
       "      <td>2025-10-23T01:50:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Cúal fue el último temblor en México hoy 22 de...   \n",
       "1  Temblor en Perú, hoy 22 de octubre: magnitud y...   \n",
       "2  Pleno del Congreso otorga el voto de confianza...   \n",
       "3  Tabla de posiciones de la Champions League 202...   \n",
       "4  EE.UU. sanciona a las dos principales petroler...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Cuál es el ultimo temblor en México y CDMX reg...   \n",
       "1  Actualización EN VIVO del último sismo en Perú...   \n",
       "2  Con 79 votos a favor, 15 en contra y 5 abstenc...   \n",
       "3  Conoce los resultados y la tabla de posiciones...   \n",
       "4  Las empresas Rosneft y Lukoil están especializ...   \n",
       "\n",
       "                                                link       date_published  \n",
       "0  https://rpp.pe/mundo/mexico/cual-fue-el-ultimo...  2025-10-22T11:42:35  \n",
       "1  https://rpp.pe/lima/desastres-naturales/temblo...  2025-10-22T07:18:58  \n",
       "2  https://rpp.pe/politica/congreso/ernesto-alvar...  2025-10-23T01:28:10  \n",
       "3  https://rpp.pe/futbol/champions-league/tabla-d...  2025-10-23T01:55:07  \n",
       "4  https://rpp.pe/mundo/actualidad/eeuu-sanciona-...  2025-10-23T01:50:40  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RPP_RSS_URL = \"https://rpp.pe/rss\"\n",
    "df = fetch_rss_items(RPP_RSS_URL, 50)\n",
    "print(f\"Fetched {len(df)} items\")\n",
    "df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "089ab53e-78f8-4027-b59f-f023e97bd3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# TOKENIZATION: Tokenize a sample article using tiktoken\n",
    "def count_tokens_tiktoken(text: str, model_name: str = \"gpt-4o-mini\") -> int:\n",
    "    \"\"\"\n",
    "    Use tiktoken if available. Provide a fallback token estimation (approx 4 chars/token).\n",
    "    \"\"\"\n",
    "    if tiktoken is None:\n",
    "        # fallback estimate: 1 token ≈ 4 characters (very rough)\n",
    "        return max(1, math.ceil(len(text) / 4))\n",
    "    try:\n",
    "        enc = tiktoken.encoding_for_model(model_name)\n",
    "    except Exception:\n",
    "        try:\n",
    "            enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        except Exception:\n",
    "            return max(1, math.ceil(len(text) / 4))\n",
    "    return len(enc.encode(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a40d95cf-3685-41c4-9ef9-f2906792c24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokens: 67\n"
     ]
    }
   ],
   "source": [
    "# Build sample text from the first RSS item\n",
    "sample_text = (df.loc[0, \"title\"] or \"\") + \"\\n\\n\" + (df.loc[0, \"description\"] or \"\")\n",
    "\n",
    "num_tokens = count_tokens_tiktoken(sample_text)\n",
    "print(\"Sample tokens:\", num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed0df50e-f01e-4de4-9830-4a1fb7d56640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needs chunking? False\n"
     ]
    }
   ],
   "source": [
    "# Decide if chunking is needed\n",
    "MODEL_TOKEN_LIMIT = 4096\n",
    "CHUNK_TOKEN_TARGET = 1000  # target tokens per chunk for embeddings/search\n",
    "needs_chunking = num_tokens > CHUNK_TOKEN_TARGET\n",
    "print(\"Needs chunking?\", needs_chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ff7f906-0738-4f88-8d1d-2759f5019c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking helper (naive words-based — can replace with tiktoken-based chunker)\n",
    "def chunk_text(text: str, chunk_size_chars: int = 2000):\n",
    "    \"\"\"Naive chunk by characters preserving whole words.\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    cur = []\n",
    "    cur_len = 0\n",
    "    for w in words:\n",
    "        if cur_len + len(w) + 1 > chunk_size_chars:\n",
    "            chunks.append(\" \".join(cur))\n",
    "            cur = [w]\n",
    "            cur_len = len(w) + 1\n",
    "        else:\n",
    "            cur.append(w)\n",
    "            cur_len += len(w) + 1\n",
    "    if cur:\n",
    "        chunks.append(\" \".join(cur))\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Example chunk preview\n",
    "if needs_chunking:\n",
    "    chunks = chunk_text(sample_text, chunk_size_chars=1500)\n",
    "    print(\"Chunks created:\", len(chunks))\n",
    "    for i, c in enumerate(chunks[:2]):\n",
    "        print(i, \"len chars:\", len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ac1b4d3-70ca-48e3-9b21-90fd07d3a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "\n",
    "# EMBEDDING: Use SentenceTransformers\n",
    "def load_sentence_transformer(model_name: str = EMBEDDING_MODEL_NAME):\n",
    "    \"\"\"\n",
    "    Load a SentenceTransformer model, or raise an error if not installed.\n",
    "    \"\"\"\n",
    "    if SentenceTransformer is None:\n",
    "        raise ImportError(\"sentence-transformers not installed. Install from requirements.txt\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fcbdcda-46b5-4025-bde7-3e9625492d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper class for embeddings\n",
    "class EmbeddingModel:\n",
    "    def __init__(self, model_name=EMBEDDING_MODEL_NAME):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "\n",
    "    def load(self):\n",
    "        self.model = load_sentence_transformer(self.model_name)\n",
    "\n",
    "    def embed_texts(self, texts: list) -> np.ndarray:\n",
    "        if self.model is None:\n",
    "            self.load()\n",
    "        # Returns numpy array of embeddings\n",
    "        return np.array(self.model.encode(texts, show_progress_bar=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2513e22-84c4-4737-99c9-2e0a7501d125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs to embed: 50\n",
      "Example doc: {'id': '0', 'text': 'Cúal fue el último temblor en México hoy 22 de octubre según SSN\\n\\nCuál es el ultimo temblor en México y CDMX registrado segun el Servicio Sismológico Nacional (SSN) hoy 22 de octubre del 2025. Consulta los últimos sismos EN VIVO para México aquí.', 'metadata': {'orig_index': 0, 'chunk_id': 0, 'title': 'Cúal fue el último temblor en México hoy 22 de octubre según SSN', 'link': 'https://rpp.pe/mundo/mexico/cual-fue-el-ultimo-temblor-en-mexico-hoy-22-de-octubre-segun-ssn-live-3013', 'date_published': '2025-10-22T11:42:35'}}\n"
     ]
    }
   ],
   "source": [
    "# Prepare documents to embed: combine title + description, chunk if needed\n",
    "docs = []\n",
    "for idx, row in df.iterrows():\n",
    "    text = (row[\"title\"] or \"\") + \"\\n\\n\" + (row[\"description\"] or \"\")\n",
    "    # If long, chunk\n",
    "    if count_tokens_tiktoken(text) > CHUNK_TOKEN_TARGET:\n",
    "        text_chunks = chunk_text(text, chunk_size_chars=1500)\n",
    "        for ci, c in enumerate(text_chunks):\n",
    "            docs.append({\n",
    "                \"id\": f\"{idx}_chunk{ci}\",\n",
    "                \"text\": c,\n",
    "                \"metadata\": {\n",
    "                    \"orig_index\": int(idx),\n",
    "                    \"chunk_id\": ci,\n",
    "                    \"title\": row[\"title\"],\n",
    "                    \"link\": row[\"link\"],\n",
    "                    \"date_published\": row[\"date_published\"],\n",
    "                },\n",
    "            })\n",
    "    else:\n",
    "        docs.append({\n",
    "            \"id\": f\"{idx}\",\n",
    "            \"text\": text,\n",
    "            \"metadata\": {\n",
    "                \"orig_index\": int(idx),\n",
    "                \"chunk_id\": 0,\n",
    "                \"title\": row[\"title\"],\n",
    "                \"link\": row[\"link\"],\n",
    "                \"date_published\": row[\"date_published\"],\n",
    "            },\n",
    "        })\n",
    "\n",
    "print(\"Total docs to embed:\", len(docs))\n",
    "print(\"Example doc:\", docs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97211464-698d-4a33-bf38-9d6fe03a4828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (50, 384)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Compute embeddings (this may take a while the first time)\n",
    "emb = EmbeddingModel()\n",
    "\n",
    "# Uncomment below lines to actually run embeddings\n",
    "# emb.load()\n",
    "# embeddings = emb.embed_texts([d[\"text\"] for d in docs])\n",
    "\n",
    "# For demo/testing (no heavy model download):\n",
    "embeddings = np.random.randn(len(docs), 384).astype(np.float32)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa48fc1e-d7b3-4612-9b92-1deba4334c57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task_1",
   "language": "python",
   "name": "task_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
